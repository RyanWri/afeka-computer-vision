{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from src.metrics import calculate_metrics, concat_and_process_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/home/ran/afeka/computer-vision/results/2025-02-04-14-17/\"\n",
    "original_file = \"baseline_no_rejection.csv\"\n",
    "experiment_file = \"equal_weights.csv\"\n",
    "confidence = 0.5\n",
    "df = pd.read_csv(os.path.join(base_folder, original_file), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_metrics = calculate_metrics(\n",
    "    df=df, label_col=\"true_label\", pred_col=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = concat_and_process_results(\n",
    "    base_folder, original_file, experiment_file, confidence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>true_label</th>\n",
       "      <th>knn</th>\n",
       "      <th>margin</th>\n",
       "      <th>mahalanobis</th>\n",
       "      <th>reject_score</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074344</td>\n",
       "      <td>0.221967</td>\n",
       "      <td>0.094250</td>\n",
       "      <td>0.390561</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.121599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078833</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110491</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.847019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.308414</td>\n",
       "      <td>0.128254</td>\n",
       "      <td>0.157616</td>\n",
       "      <td>0.594284</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255491</td>\n",
       "      <td>0.158212</td>\n",
       "      <td>0.413703</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109067</td>\n",
       "      <td>0.320562</td>\n",
       "      <td>0.158520</td>\n",
       "      <td>0.588148</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probability  prediction  true_label       knn    margin  mahalanobis  \\\n",
       "0     0.472125           0           0  0.074344  0.221967     0.094250   \n",
       "1     0.121599           0           0  0.078833  0.031658     0.000000   \n",
       "2     0.847019           1           1  0.308414  0.128254     0.157616   \n",
       "3     0.070324           0           0  0.000000  0.255491     0.158212   \n",
       "4     0.061441           0           0  0.109067  0.320562     0.158520   \n",
       "\n",
       "   reject_score  rejected  \n",
       "0      0.390561     False  \n",
       "1      0.110491     False  \n",
       "2      0.594284      True  \n",
       "3      0.413703     False  \n",
       "4      0.588148      True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_metrics = calculate_metrics(\n",
    "    df=data[data[\"rejected\"]], label_col=\"true_label\", pred_col=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: accuracy ------------ 0.7821044921875\n",
      "after rejection: accuracy ---------- [0.7883940620782726]\n",
      "\n",
      "original: precision ------------ 0.8195054945054945\n",
      "after rejection: precision ---------- [0.8285198555956679]\n",
      "\n",
      "original: recall ------------ 0.7256142057893457\n",
      "after rejection: recall ---------- [0.7340085287846482]\n",
      "\n",
      "original: f1_score ------------ 0.7697071345632821\n",
      "after rejection: f1_score ---------- [0.7784058790276993]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in original_metrics.keys():\n",
    "    print(f\"original: {key} ------------ {original_metrics[key]}\")\n",
    "    print(f\"after rejection: {key} ---------- {[equal_metrics[key]]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
